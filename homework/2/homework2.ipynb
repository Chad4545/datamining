{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  201111774 응용통계학과 박성진\n",
    "\n",
    "## (Homework)                                  \n",
    "\n",
    "### 1. Write an R code as above(LASSO)\n",
    "\n",
    "### 2. Find and report some prorperties and algorithms for each loss(square, absolute, Huber, LASSO)\n",
    "\n",
    "### 3. Normal equation 증명(LSE)\n",
    "    - check some statistical properties of LSE such as unbiasedness in other classes\n",
    "\n",
    "### 4. Draw the table for the analysis of variance(ANOVA)\n",
    "\n",
    "### 5. AIC 증명\n",
    "    -find other model assessment measures\n",
    "    \n",
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Find and report some prorperties and algorithms for each loss(square, absolute, Huber, LASSO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Various loss functions\n",
    "\n",
    "- Popular choices for $L(B_0,B_1)$ for the simple linear regression model\n",
    "\n",
    "\n",
    "### square loss (least squares estimation)\n",
    "\n",
    "$$L(B_0,B_1) = (y-B_0,B_1x)^2$$\n",
    "\n",
    "### absolute loss (least absolute deviation estimation)\n",
    "\n",
    "$$L(B_0,B_1) = |\\,y − B_0 − B_1x\\,|$$ \n",
    "\n",
    "### Huber loss (Huberiezed estimation)\n",
    "$$L(B_0,B_1) = $$\n",
    "\n",
    "$∗ \\,t = y − B_0 − B_1x$\n",
    "\n",
    "$∗ \\,δ > 0: Huber’s tuning parameter (Huber’s recommendation δ = 1.345)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Normal equation(LSE) proof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i번째 sample ($x_i$,$y_i$)에 관한 회귀모형을 다음으로 표현할 때\n",
    "\n",
    "- $$ y_i =  B_0 + B_1x_i +\\epsilon $$\n",
    "\n",
    "Loss 함수는 $L(B_0,B_1) = (y-B_0-B_1x)^2$ 과 같아서\n",
    "\n",
    "Risk 함수는 $R_n(B_0,B_1) =  \\sum_{i=1}^n(y_i-(B_0 + B_1x_i))^2/2n$ 이다.\n",
    "\n",
    "이를 최소로 하는 $B_0$과 $B_1$의 값을 이들의 추정값 $\\hat B_0, \\hat B_1$ 로 하는 방법이 **LSE** 이다.\n",
    "\n",
    "$R_n(B_0,B_1)$을 최소화 시키는 $B_0, B_1$을 구하기 위하여 $R_n(B_0,B_1)$을 $B_1$과 $B_0$로 각각 편미분하여 다음의 결과를 얻는다\n",
    "\n",
    "\n",
    "- $$\\nabla R_n(B_0, B_1) = \\begin{pmatrix} -\\sum_{i=1}^n(y_i-(B_0 + B_1x_i)/n  \\\\\n",
    "-\\sum_{i=1}^nx_i(y_i-(B_0 + B_1x_i)/n \\end{pmatrix}$$\n",
    "\n",
    "위의 편미분 값을 0으로 만드는 $B_0, B_1$을 $\\hat B_0, \\hat B_1$으로 대치하고 정리하면\n",
    "\n",
    "- $$ \\hat B_0n + \\hat B_1\\sum x_i = \\sum y_i$$\n",
    "\n",
    "- $$ \\hat B_0\\sum x_i + \\hat B_1\\sum x_i^2 = \\sum x_iy_i$$\n",
    "\n",
    "이 되는데 이 식을 **Normal equation**이라 부르고, 이를 $\\hat B_0$과 $\\hat B_1$에 대해 풀면,\n",
    "\n",
    "\n",
    "- $\\hat B_0 = \\bar y -\\hat B_1\\bar x$\n",
    "\n",
    "\n",
    "- $\\hat B_1 =\\frac{\\sum_{i=1}^n(x_i - \\bar x)(y_i - \\bar y)}{ \\sum_{i=1}^n(x_i -\\bar x)^2}$  이고,\n",
    "\n",
    "\n",
    "표현을 간단히 하기 위하여 \n",
    "\n",
    "\n",
    "- $S_{xx} = \\sum (x_i - \\bar x)^2$\n",
    "\n",
    "- $S_{yy} = \\sum (y_i - \\bar y)^2$\n",
    "\n",
    "- $S_{xy} = \\sum (x_i - \\bar x)(y_i - \\bar y)$ \n",
    "\n",
    "을 사용하기로 하면 \n",
    "\n",
    "\n",
    "\n",
    "- $\\hat B_0 = \\bar y - \\hat B_1\\bar x$\n",
    "\n",
    "- $\\hat B_1 = \\frac{S_{xy}}{S_{xx}}$ \n",
    "\n",
    "로 표현할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implications for the Estimators\n",
    "\n",
    "- $\\hat B_1$ is normally distributed with mean $B_1$ and variance $\\sigma^2 \\over S_{xx}$\n",
    "\n",
    "- $\\hat B_0$ is normally distributed with mean $B_0$ and variance $\\sigma^2 \\frac{\\sum_{i=1}^nx_i^2}{nS_{xx}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. ANOVA TABLE\n",
    "\n",
    "---\n",
    "\n",
    "<table>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th align=\"center\">Source</th>\n",
    "      <th align=\"center\">SS</th>\n",
    "      <th align=\"center\">DF</th>\n",
    "      <th align=\"center\">MS</th>\n",
    "      <th align=\"center\">F</th>\n",
    "      <th align=\"center\">P</th>  \n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td align=\"center\">Factor</td>\n",
    "      <th align=\"center\">SSR</th>\n",
    "      <th align=\"center\">1</th>\n",
    "      <th align=\"center\">SSR</th>\n",
    "      <th align=\"center\">MSR/MSE</th>\n",
    "      <th align=\"center\">F(1, n-2; a)</th>    \n",
    "   </tr>\n",
    "    <tr>\n",
    "      <td align=\"center\">Error</td>\n",
    "      <th align=\"center\">SSE</th>\n",
    "      <th align=\"center\">n-2</th>\n",
    "      <th align=\"center\">MSE$=\\frac{SSE}{n-2}$</th>    \n",
    "\n",
    "   </tr>\n",
    "    <tr>\n",
    "      <td align=\"center\">Total</td>\n",
    "      <td align=\"center\">SST</td>\n",
    "      <td align=\"center\">n-1</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. AIC(Akaike's Information Criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- AIC는 여러 통계 모델들의 성능을 서로 비교할 수 있게 해줌.\n",
    "\n",
    "\n",
    "- 데이터에 대한 여러 모델 세트가 주어지면 더 나은 모델은 최소 AIC 값을 갖는 모델.\n",
    "\n",
    "- 따라서 AIC는 goodness of fit(가능도에 의해 구해진)을 보장하지만, 추정된 회귀계수의 수에 따라 증가하는 페널티도 포함.\n",
    "\n",
    "- 모델에서 설명변수의 수를 늘리면 거의 goodness of fit이 향상하므로, 패널티는 overfitting을 방지함.\n",
    "\n",
    "- AIC 값은 두 모델의 관측치 개수가 거의 동일할 때만 비교해야함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
