variables=seq(10,100,by=10)
result[1,i] = variables[i]
data = make_train_test(p=variables[i],n=10000)
pred_error = pred_err(data)
result[2,i] = pred_error
}
result
matplot(result[1,],result[2,],type="h",
ylab = expression("pred_error"),
xlab = expression("# of variables"))
result = matrix(NA,2,100)
rownames(result)=c("# of variables","pred_error")
for(i in seq(1,100)){
variables=seq(1,100,by=1)
result[1,i] = variables[i]
data = make_train_test(p=variables[i],n=10000)
pred_error = pred_err(data)
result[2,i] = pred_error
}
result
matplot(result[1,],result[2,],type="h",
ylab = expression("pred_error"),
xlab = expression("# of variables"))
make_train_test = function(p,n=10000,ratio=0.8){
b.vec = 1/(1:p)
x.mat = matrix(rnorm(n*p),ncol=p)
y.vec = x.mat%*%b.vec + rnorm(n) # 마지막텀은 오차
xy.df = data.frame(cbind(y.vec,x.mat))
a <- createDataPartition(xy.df[,1], p = 0.8, list=FALSE)
train <- xy.df[a,]
test <- xy.df[-a,]
return(list(train=train, test=test,beta=b.vec))
}
pred_err = function(data){
train = as.data.frame(data$train)
test = as.data.frame(data$test)
lm.fit = lm(X1~.,data=train)
beta = as.data.fram(data$beta)
b.fit = coef(lm(X1~.,data=train))
pred_error=mean((beta-b.fit)^2)
return (pred_error)
}
result = matrix(NA,2,100)
rownames(result)=c("# of variables","pred_error")
for(i in seq(1,100)){
variables=seq(1,100,by=1)
result[1,i] = variables[i]
data = make_train_test(p=variables[i],n=10000)
pred_error = pred_err(data)
result[2,i] = pred_error
}
pred_err = function(data){
train = as.data.frame(data$train)
test = as.data.frame(data$test)
lm.fit = lm(X1~.,data=train)
beta = as.data.frame(data$beta)
b.fit = coef(lm(X1~.,data=train))
pred_error=mean((beta-b.fit)^2)
return (pred_error)
}
result = matrix(NA,2,100)
rownames(result)=c("# of variables","pred_error")
for(i in seq(1,100)){
variables=seq(1,100,by=1)
result[1,i] = variables[i]
data = make_train_test(p=variables[i],n=10000)
pred_error = pred_err(data)
result[2,i] = pred_error
}
result
data = make_train_test(100,10000)
train = as.data.frame(data$train)
test = as.data.frame(data$test)
lm.fit = lm(X1~.,data=train)
beta = as.data.frame(data$beta)
View(beta)
b.fit = coef(lm(X1~.,data=train))
beta = as.vec(data$beta)
beta = vec(data$beta)
beta = data$beta
b.fit = coef(lm(X1~.,data=train))
beta[:5]
beta[1:5]
b.fit[1:5]
b.fit[2:6]
b.fit[-1]
type(b.fit[-1])
beta-b.fit[-1]
make_train_test = function(p,n=10000,ratio=0.8){
b.vec = 1/(1:p)
x.mat = matrix(rnorm(n*p),ncol=p)
y.vec = x.mat%*%b.vec + rnorm(n) # 마지막텀은 오차
xy.df = data.frame(cbind(y.vec,x.mat))
a <- createDataPartition(xy.df[,1], p = 0.8, list=FALSE)
train <- xy.df[a,]
test <- xy.df[-a,]
return(list(train=train, test=test,beta=b.vec))
}
pred_err = function(data){
train = as.data.frame(data$train)
test = as.data.frame(data$test)
lm.fit = lm(X1~.,data=train)
beta =data$beta
b.fit = coef(lm(X1~.,data=train))[-1]
pred_error=mean((beta-b.fit)^2)
return (pred_error)
}
result = matrix(NA,2,100)
rownames(result)=c("# of variables","pred_error")
for(i in seq(1,100)){
variables=seq(1,100,by=1)
result[1,i] = variables[i]
data = make_train_test(p=variables[i],n=10000)
pred_error = pred_err(data)
result[2,i] = pred_error
}
result
matplot(result[1,],result[2,],type="h",
ylab = expression("pred_error"),
xlab = expression("# of variables"))
min_error = min(result[2,])
inds = which(result[2,] == min_error, arr.ind=TRUE)
inds
View(result)
?min()
pmin_error = min(result[2,])
View(result)
inds = which(result[2,] == pmin_error, arr.ind=TRUE)
inds
min_error = pmin(result[2,])
inds = which(result[2,] == min_error, arr.ind=TRUE)
inds
'''
1. 변수의 갯수 증감에 따른 비교
2. 샘플의 갯수 증감에 따른 비교
3. 샘플이 normal dist를 따를때, 분산에 따른 비교
4. 샘플이 t dist를 따를때, 자유도에 따른 비교
비교 기준은 y와 yhat의 mse로 한다.
'''
'''
1. 변수의 갯수에 따른 비교
'''
library(caret)
'''
p = 사용할 설명변수의 갯수
n = 사용할 데이터의 수
ratio = train/test 비율 (default 8:2)
실험 1에서는 n = 10000으로 고정 후
p 를 1에서 100 까지 늘려본다.
'''
make_train_test = function(p,n=10000,ratio=0.8){
b.vec = 1/(1:p)
x.mat = matrix(rnorm(n*p),ncol=p)
y.vec = x.mat%*%b.vec + rnorm(n) # 마지막텀은 오차
xy.df = data.frame(cbind(y.vec,x.mat))
a <- createDataPartition(xy.df[,1], p = 0.8, list=FALSE)
train <- xy.df[a,]
test <- xy.df[-a,]
return(list(train=train, test=test,beta=b.vec))
}
pred_err = function(data){
train = as.data.frame(data$train)
test = as.data.frame(data$test)
lm.fit = lm(X1~.,data=train)
beta =data$beta
b.fit = coef(lm(X1~.,data=train))[-1]
pred_error=mean((beta-b.fit)^2)
return (pred_error)
}
result = matrix(NA,2,100)
rownames(result)=c("# of variables","pred_error")
for(i in seq(1,100)){
variables=seq(1,100,by=1)
result[1,i] = variables[i]
data = make_train_test(p=variables[i],n=10000)
pred_error = pred_err(data)
result[2,i] = pred_error
}
matplot(result[1,],result[2,],type="h",
ylab = expression("pred_error"),
xlab = expression("# of variables"))
title(main = "experiment_1")
result = matrix(NA,2,25)
rownames(result)=c("# of variables","pred_error")
for(i in seq(5,30)){
variables=seq(5,30,by=1)
result[1,i] = variables[i]
data = make_train_test(p=variables[i],n=10000)
pred_error = pred_err(data)
result[2,i] = pred_error
}
for(i in seq(1,25)){
variables=seq(5,30,by=1)
result[1,i] = variables[i]
data = make_train_test(p=variables[i],n=10000)
pred_error = pred_err(data)
result[2,i] = pred_error
}
result
matplot(result[1,],result[2,],type="h",
ylab = expression("pred_error"),
xlab = expression("# of variables"))
title(main = "experiment_2")
min_error = min(result[2,])
min_error
?seed()
?set.seed()
set.seed(1)
set.seed(1)
make_train_test = function(p,n=10000,ratio=0.8){
b.vec = 1/(1:p)
x.mat = matrix(rnorm(n*p),ncol=p)
y.vec = x.mat%*%b.vec + rnorm(n) # 마지막텀은 오차
xy.df = data.frame(cbind(y.vec,x.mat))
a <- createDataPartition(xy.df[,1], p = 0.8, list=FALSE)
train <- xy.df[a,]
test <- xy.df[-a,]
return(list(train=train, test=test,beta=b.vec))
}
pred_err = function(data){
train = as.data.frame(data$train)
test = as.data.frame(data$test)
lm.fit = lm(X1~.,data=train)
beta =data$beta
b.fit = coef(lm(X1~.,data=train))[-1]
pred_error=mean((beta-b.fit)^2)
return (pred_error)
}
result = matrix(NA,2,10)
result = matrix(NA,2,10)
rownames(result)=c("# of variables","pred_error")
for(i in seq(1,10)){
variables=seq(1000,10000,by=1000)
result[1,i] = variables[i]
data = make_train_test(p=10,n=variables[i])
pred_error = pred_err(data)
result[2,i] = pred_error
}
result
result = matrix(NA,2,10)
rownames(result)=c("# of variables","pred_error")
for(i in seq(1,10)){
variables=seq(1000,10000,by=1000)
result[1,i] = 10
data = make_train_test(p=10,n=variables[i])
pred_error = pred_err(data)
result[2,i] = pred_error
}
result
matplot(result[1,],result[2,],type="h",
ylab = expression("pred_error"),
xlab = expression("# of variables"))
result = matrix(NA,2,10)
rownames(result)=c("# of samples","pred_error")
for(i in seq(1,10)){
variables=seq(1000,10000,by=1000)
result[1,i] = 10
data = make_train_test(p=10,n=variables[i])
pred_error = pred_err(data)
result[2,i] = pred_error
}
result
result = matrix(NA,2,10)
rownames(result)=c("# of samples","pred_error")
for(i in seq(1,10)){
variables=seq(1000,10000,by=1000)
result[1,i] = variables[i]
data = make_train_test(p=10,n=variables[i])
pred_error = pred_err(data)
result[2,i] = pred_error
}
result
matplot(result[1,],result[2,],type="h",
ylab = expression("pred_error"),
xlab = expression("# of samples"))
result = matrix(NA,2,100)
rownames(result)=c("# of samples","pred_error")
for(i in seq(1,100)){
variables=seq(100,10000,by=100)
result[1,i] = variables[i]
data = make_train_test(p=10,n=variables[i])
pred_error = pred_err(data)
result[2,i] = pred_error
}
result
matplot(result[1,],result[2,],type="h",
ylab = expression("pred_error"),
xlab = expression("# of samples"))
matplot(result[1,],result[2,],type="h",
ylim =(0,0.5)
ylab = expression("pred_error"),
xlab = expression("# of samples"))
matplot(result[1,],result[2,],type="h",
ylim =(0,0.5),
ylab = expression("pred_error"),
xlab = expression("# of samples"))
matplot(result[1,],result[2,],type="h",
ylim =(0,0.5),
ylab = expression("pred_error"),
xlab = expression("# of samples"))
matplot(result[1,],result[2,],type="h",
ylim =(0,0.5),
ylab = expression("pred_error"),
xlab = expression("# of samples"))
title(main = "experiment_1")
matplot(result[1,],result[2,],type="h",
ylim =(0,0.1),
ylab = expression("pred_error"),
xlab = expression("# of samples"))
?matplot
matplot(result[1,],result[2,],type="h",
ylab = expression("pred_error"),
xlab = expression("# of samples"))
title(main = "experiment_1")
?rnorm
set.seed(1)
library(caret)
?rnorm
make_data = function(p=10,n=5000,sd_value=1){
b.vec = 1/(1:p)
x.mat = matrix(rnorm(n*p),ncol=p)
y.vec = x.mat%*%b.vec + rnorm(n,sd=sd_value) # 마지막텀은 오차
xy.df = data.frame(cbind(y.vec,x.mat))
return(list(data=xy.df,beta=b.vec))
}
pred_err = function(data){
xy.df = as.data.frame(data$data)
lm.fit = lm(X1~.,data=xy.df)
beta =data$beta
b.fit = coef(lm.fit)[-1]
pred_error=mean((beta-b.fit)^2)
return (pred_error)
}
set.seed(1)
library(caret)
make_data = function(p=10,n=5000,sd_value=1){
b.vec = 1/(1:p)
x.mat = matrix(rnorm(n*p),ncol=p)
y.vec = x.mat%*%b.vec + rnorm(n,sd=sd_value) # 마지막텀은 오차
xy.df = data.frame(cbind(y.vec,x.mat))
return(list(data=xy.df,beta=b.vec))
}
pred_err = function(data){
xy.df = as.data.frame(data$data)
lm.fit = lm(X1~.,data=xy.df)
beta =data$beta
b.fit = coef(lm.fit)[-1]
pred_error=mean((beta-b.fit)^2)
return (pred_error)
}
result = matrix(NA,2,10)
rownames(result)=c("standard deviation","pred_error")
for(i in seq(1,10)){
variables=seq(1,10,by=1)
result[1,i] = variables[i]
data = make_data(p=10,n=5000,sd_value = variables[i])
pred_error = pred_err(data)
result[2,i] = pred_error
}
result
matplot(result[1,],result[2,],type="h",
ylab = expression("pred_error"),
xlab = expression("standard deviation"))
title(main = "experiment_1")
result = matrix(NA,2,10)
result = matrix(NA,2,100)
rownames(result)=c("standard deviation","pred_error")
for(i in seq(1,100)){
variables=seq(0.5,3,length.out = 100)
result[1,i] = variables[i]
data = make_data(p=10,n=5000,sd_value = variables[i])
pred_error = pred_err(data)
result[2,i] = pred_error
}
result
matplot(result[1,],result[2,],type="h",
ylab = expression("pred_error"),
xlab = expression("standard deviation"))
title(main = "experiment_1")
?t()
?rt()
set.seed(1)
make_data = function(p=10,n=5000,df_value=1){
b.vec = 1/(1:p)
x.mat = matrix(rnorm(n*p),ncol=p)
y.vec = x.mat%*%b.vec + rt(n,df=df_value) # 마지막텀은 오차
xy.df = data.frame(cbind(y.vec,x.mat))
return(list(data=xy.df,beta=b.vec))
}
pred_err = function(data){
xy.df = as.data.frame(data$data)
lm.fit = lm(X1~.,data=xy.df)
beta =data$beta
b.fit = coef(lm.fit)[-1]
pred_error=mean((beta-b.fit)^2)
return (pred_error)
}
result = matrix(NA,2,30)
rownames(result)=c("Degree of freedom","pred_error")
for(i in seq(1,30)){
variables=seq(1,30,by=1)
result[1,i] = variables[i]
data = make_data(p=10,n=5000,df_value = variables[i])
pred_error = pred_err(data)
result[2,i] = pred_error
}
result
matplot(result[1,],result[2,],type="h",
ylab = expression("pred_error"),
xlab = expression("Degree of freedom"))
title(main = "experiment_1")
set.seed(1)
make_data = function(p=10,n=10000,df_value=1){
b.vec = 1/(1:p)
x.mat = matrix(rnorm(n*p),ncol=p)
y.vec = x.mat%*%b.vec + rt(n,df=df_value) # 마지막텀은 오차
xy.df = data.frame(cbind(y.vec,x.mat))
return(list(data=xy.df,beta=b.vec))
}
pred_err = function(data){
xy.df = as.data.frame(data$data)
lm.fit = lm(X1~.,data=xy.df)
beta =data$beta
b.fit = coef(lm.fit)[-1]
pred_error=mean((beta-b.fit)^2)
return (pred_error)
}
result = matrix(NA,2,30)
rownames(result)=c("Degree of freedom","pred_error")
for(i in seq(1,30)){
variables=seq(1,30,by=1)
result[1,i] = variables[i]
data = make_data(p=10,n=10000,df_value = variables[i])
pred_error = pred_err(data)
result[2,i] = pred_error
}
result
min_error = min(result[2,])
matplot(result[1,],result[2,],type="h",
ylab = expression("pred_error"),
xlab = expression("Degree of freedom"))
title(main = "experiment_1")
matplot(result[1,],result[2,],type="h",
ylab = expression("pred_error"),
xlab = expression("Degree of freedom")
ylim = 0.001)
matplot(result[1,],result[2,],type="h",
ylab = expression("pred_error"),
xlab = expression("Degree of freedom"),
ylim = 0.001)
matplot(result[1,],result[2,],type="h",
ylab = expression("pred_error"),
xlab = expression("Degree of freedom"),
ylim = 0.01)
matplot(result[1,],result[2,],type="h",
ylab = expression("pred_error"),
xlab = expression("Degree of freedom"),
ylim = 0.01)
matplot(result[1,],result[2,],type="h",
ylab = expression("pred_error"),
xlab = expression("Degree of freedom"),
ylim = c(0,0.001))
title(main = "experiment_1")
matplot(result[1,],result[2,],type="h",
ylab = expression("pred_error"),
xlab = expression("Degree of freedom"),
ylim = c(0,0.01))
matplot(result[1,],result[2,],type="h",
ylab = expression("pred_error"),
xlab = expression("Degree of freedom"),
ylim = c(0,0.008))
title(main = "experiment_1")
rm(list=ls())
setwd("/Users/sungjinpark/Desktop/OneDrive - konkuk.ac.kr/datamining/5wk")
getwd()
xy.df =  read.csv("old.sam.for.reg.fit.csv")
nxy.df = read.csv("old.sam.for.reg.pred.csv")
p = dim(xy.df)[2]  ;p
c.set = 2:p ; c.set
opt = c()
error = c()
for(l in 1:p-1){
e.vec = rep(1000,p-1-length(opt))
for(i in c.set[!c.set %in% opt]){
lm.fit = lm(sensitivity ~. , data = xy.df[,c(1,opt,i)])
ny = predict(lm.fit, newdata = nxy.df[,c(1,opt,i)])
e.vec[i] = mean(abs(nxy.df[,1]-ny))
}
opt = c(opt,which.min(e.vec)) ; opt
error = c(error,e.vec[which.min(e.vec)]) ;error
}
library(data.table)
#install.packages("data.table")
print(opt)
print(error)
name <- c("opt", "error")
rst.table <- data.table(opt,error) ; rst.table
print("Selected Variables")
opt[1:which.min(error)]
plot(1:20,error)
rm(list=ls())
setwd("/Users/sungjinpark/Desktop/OneDrive - konkuk.ac.kr/datamining/5wk")
getwd()
xy.df =  read.csv("old.sam.for.reg.fit.csv")
nxy.df = read.csv("old.sam.for.reg.pred.csv")
predict(lm.fit,newdata=nxy.df) #?? ?İ? ?ؿ? ??�� ??�� ?????? ??Ÿ??.
setwd("/Users/sungjinpark/Desktop/OneDrive - konkuk.ac.kr/datamining/5wk")
getwd()
xy.df =  read.csv("old.sam.for.reg.fit.csv")
nxy.df = read.csv("old.sam.for.reg.pred.csv")
p = dim(xy.df)[2]  ;p
c.set = 2:p ; c.set
