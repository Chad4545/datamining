b.vec = c(-1,1)
View(x.mat)
x.mat
# loss funtion implement
x.mat%*%b.vec
############################################################
# square loss for simple linear regression
sq.loss.fun = function(y.vec,x.vec,b.vec){
x.mat = cbind(1,x.vec)
y_hat = x.mat%*%b.vec
t.vec =  y - y_hat
loss = sum(t.vec^2)
return(loss)
}
# L2_squere
sq.loss.fun(y.vec,x.vec,b.vec)
y.vec = c(3,-2,1)
x.vec = c(-1,2,2)
b.vec = c(-1,1)
# L2_squere
sq.loss.fun(y.vec,x.vec,b.vec)
t.vec =  y.vec - y_hat
loss = sum(t.vec^2)
return(loss)
############################################################
# square loss for simple linear regression
sq.loss.fun = function(y.vec,x.vec,b.vec){
x.mat = cbind(1,x.vec)
y_hat = x.mat%*%b.vec
t.vec =  y.vec - y_hat
loss = sum(t.vec^2)
return(loss)
}
y.vec = c(3,-2,1)
x.vec = c(-1,2,2)
b.vec = c(-1,1)
# L2_squere
sq.loss.fun(y.vec,x.vec,b.vec)
sq.loss.fun(y.vec,x.vec,b.vec=c(1,1))
sxx = sum((x.vec-mean(x.vec))^2)
sxx
sx = (x.vec-mean(x.vec))
sx
sy
sy = (y.vec-mean(y.vec))
sy
sxy = sum(sx*sy)
sxy
b.vec = c(NA,NA)
b.vec[2] = sxy/sxx
b.vec
b.vec[1] = mean(y.vec) - b.vec[2]*mean(x.vec)
b.vec
############################################################
sq.loss.fun(y.vec,x.vec,b.vec)
# 3/11 _ 2wk
getwd()
############################################################
# square loss for simple linear regression
sq.loss.fun = function(y.vec,x.vec,b.vec){
x.mat = cbind(1,x.vec)
y_hat = x.mat%*%b.vec
t.vec =  y.vec - y_hat
loss = sum(t.vec^2)
return(loss)
}
y.vec = c(3,-2,1)
x.vec = c(-1,2,2)
# 대입 10000번 하겠다.
b0.vec = seq(-10,10,length.out=100)
b1.vec = seq(-10,10,length.out=100)
loss.mat = matrix(NA,100,100)
for(b0. in b0.vec){
for(b1 in b1.vec){
b.vec = c(b0.vec[i],b1.vec[j])
loss.mat[i,j=]sq.loss.fun(y.vec,x.vec,b.vec)
}
}
for(b0. in b0.vec){
for(b1 in b1.vec){
b.vec = c(b0.vec[i],b1.vec[j])
loss.mat[i,j=]sq.loss.fun(y.vec,x.vec,b.vec)
}
}
loss.mat[i,j]=sq.loss.fun(y.vec,x.vec,b.vec)
for(b0. in b0.vec){
for(b1 in b1.vec){
b.vec = c(b0.vec[i],b1.vec[j])
loss.mat[i,j]=sq.loss.fun(y.vec,x.vec,b.vec)
}
}
for(i in b0.vec){
for(j in b1.vec){
b.vec = c(b0.vec[i],b1.vec[j])
loss.mat[i,j]=sq.loss.fun(y.vec,x.vec,b.vec)
}
}
loss.mat = matrix(NA,100,100)
for(i in b0.vec){
for(j in b1.vec){
b.vec = c(b0.vec[i],b1.vec[j])
loss.mat[i,j]=sq.loss.fun(y.vec,x.vec,b.vec)
}
}
############################################################
# square loss for simple linear regression
sq.loss.fun = function(y.vec,x.vec,b.vec){
x.mat = cbind(1,x.vec)
y_hat = x.mat%*%b.vec
t.vec =  y.vec - y_hat
loss = sum(t.vec^2)
return(loss)
}
y.vec = c(3,-2,1)
x.vec = c(-1,2,2)
# 대입 10000번 하겠다.
b0.vec = seq(-10,10,length.out=100)
b1.vec = seq(-10,10,length.out=100)
loss.mat = matrix(NA,100,100)
for(i in b0.vec){
for(j in b1.vec){
b.vec = c(b0.vec[i],b1.vec[j])
loss.mat[i,j]=sq.loss.fun(y.vec,x.vec,b.vec)
}
}
?contour
############################################################
# square loss for simple linear regression
sq.loss.fun = function(y.vec,x.vec,b.vec){
x.mat = cbind(1,x.vec)
y_hat = x.mat%*%b.vec
t.vec =  y.vec - y_hat
loss = sum(t.vec^2)
return(loss)
}
y.vec = c(3,-2,1)
x.vec = c(-1,2,2)
# 대입 10000번 하겠다.
b0.vec = seq(-10,10,length.out=100)
b1.vec = seq(-10,10,length.out=100)
loss.mat = matrix(NA,100,100)
for(i in b0.vec){
for(j in b1.vec){
b.vec = c(b0.vec[i],b1.vec[j])
loss.mat[i,j]=sq.loss.fun(y.vec,x.vec,b.vec)
}
}
sq.loss.fun <- function(y.vec, x.vec, b.vec){
x.mat = cbind(1,x.vec)
y.hat = x.mat%*%b.vec
res.vec = y.vec - y.hat
loss = sum(rec.vec^2)
return(loss)
}
y.vec = c(3,-2,1)
x.vec = c(-1,2,2)
b.vec = c(-1,1)
# L2_squere
sq.loss.fun(y.vec,x.vec,b.vec)
sq.loss.fun <- function(y.vec, x.vec, b.vec){
x.mat = cbind(1,x.vec)
y.hat = x.mat%*%b.vec
res.vec = y.vec - y.hat
loss = sum(res.vec^2)
return(loss)
}
y.vec = c(3,-2,1)
x.vec = c(-1,2,2)
b.vec = c(-1,1)
# L2_squere
sq.loss.fun(y.vec,x.vec,b.vec)
sq.loss.fun(y.vec,x.vec,b.vec=c(1,1))
sq.loss.fun(y.vec,x.vec,b.vec=c(1,0))
# 대입 10000번 하겠다.
b0.vec = seq(-10,10,length.out=100)
b1.vec = seq(-10,10,length.out=100)
loss.mat = matrix(NA,100,100)
for(i in b0.vec){
for(j in b1.vec){
b.vec = c(b0.vec[i],b1.vec[j])
loss.mat[i,j]=sq.loss.fun(y.vec,x.vec,b.vec)
}
}
b.vec = cbind(b0.vec[i],b1.vec[j])
loss.mat[i,j]=sq.loss.fun(y.vec,x.vec,b.vec)
for(j in b1.vec){
b.vec = cbind(b0.vec[i],b1.vec[j])
loss.mat[i,j]=sq.loss.fun(y.vec,x.vec,b.vec)
}
for(i in b0.vec){
for(j in b1.vec){
b.vec = cbind(b0.vec[i],b1.vec[j])
loss.mat[i,j]=sq.loss.fun(y.vec,x.vec,b.vec)
}
}
contour(b0.vec,b1.vec,loss.mat,nlevels=100)
View(loss.mat)
View(b.vec)
y.vec = c(3,-2,1)
x.vec = c(-1,2,2)
t.vec = c(1,2,3,4)
test = cbind(1,t.vec)
View(test)
btest = c(-1,1)
btest
y__hat =btest%*%test
y__hat =test %*% btest
View(y__hat)
View(test)
# square loss funtion for
sq.loss.fun <- function(y.vec, x.vec, b.vec){
x.mat = cbind(1,x.vec)
y.hat = x.mat%*%b.vec
res.vec = y.vec - y.hat
loss = sum(res.vec^2)
return(loss)
}
y.vec = c(3,-2,1)
x.vec = c(-1,2,2)
b.vec = c(-1,1)
# square loss funtion for
sq.loss.fun <- function(y.vec, x.vec, b.vec){
x.mat = cbind(1,x.vec)
y.hat = x.mat%*%b.vec
res.vec = y.vec - y.hat
loss = sum(res.vec^2)
return(loss)
}
y.vec = c(3,-2,1)
x.vec = c(-1,2,2)
b.vec = c(-1,1)
# L2_squere
sq.loss.fun(y.vec,x.vec,b.vec)
sq.loss.fun(y.vec,x.vec,b.vec=c(1,1))
sq.loss.fun(y.vec,x.vec,b.vec=c(1,0))
# 대입 10000번 하겠다.
b0.vec = seq(-10,10,length.out=100)
b1.vec = seq(-10,10,length.out=100)
for(i in b0.vec){
for(j in b1.vec){
b.vec = c(b0.vec[i],b1.vec[j])
loss.mat[i,j]=sq.loss.fun(y.vec,x.vec,b.vec)
}
}
# square loss funtion for
sq.loss.fun <- function(y.vec, x.mat, b.vec){
y.hat = x.mat%*%b.vec
res.vec = y.vec - y.hat
loss = sum(res.vec^2)
return(loss)
}
y.vec = c(3,-2,1)
x.vec = c(-1,2,2)
x.mat = c(1,x.vec)
x.mat = cbind(1,x.vec)
b.vec = c(-1,1)
# L2_squere
sq.loss.fun(y.vec,x.vec,b.vec)
# L2_squere
sq.loss.fun(y.vec,x.mat,b.vec)
sq.loss.fun(y.vec,x.mat,b.vec=c(1,1))
sq.loss.fun(y.vec,x.mat,b.vec=c(1,0))
# 대입 10000번 하겠다.
b0.vec = seq(-10,10,length.out=100)
b1.vec = seq(-10,10,length.out=100)
loss.mat = matrix(NA,100,100)
for(i in b0.vec){
for(j in b1.vec){
b.vec = c(b0.vec[i],b1.vec[j])
loss.mat[i,j]=sq.loss.fun(y.vec,x.mat,b.vec)
}
}
b0.vec[1]
for(i in b0.vec){
for(j in b1.vec){
b.vec = c(i,j)
loss.mat[i,j]=sq.loss.fun(y.vec,x.mat,b.vec)
}
}
contour(b0.vec,b1.vec,loss.mat,nlevels=100)
# square loss funtion for
sq.loss.fun <- function(y,x.mat,b){
r.vec = y - x.mat%*%b
loss = sum(r.vec^2)
return(loss)
}
# square loss funtion for
sq.loss.fun <- function(y,x.mat,b){
r.vec = y - x.mat%*%b
loss = sum(r.vec^2)
return(loss)
}
# y, x.mat
y = c(1,4,10)
x = c(3,2,5)
x.mat = cbind(1,x)
b.vec.01 = c(1,1)
sq.loss.fun(y,x.mat,b.vec.01)
sq.loss.fun(y,x.mat,b.vec.02)
b.vec.02 = c(1,0)
sq.loss.fun(y,x.mat,b.vec.02)
sxx = sum((x-mean(x))^2)
sxx
sx = (x-mean(x))
sx
sy = (y-mean(y))
sy
sxy = sum(sx*sy)
sxy
b.vec = c(NA,NA)
b.vec[2] = sxy/sxx
b.vec
b.vec[1] = mean(y.vec) - b.vec[2]*mean(x.vec)
b.vec[1] = mean(y) - b.vec[2]*mean(x.vec)
vec
b.vec[1] = mean(y) - b.vec[2]*mean(x)
b.vec
sq.loss.fun(y,x.mat,b.vec.02)
x.mat = cbind(1,x)
sq.loss.fun(y,x.mat,b.vec.02)
square_loss = function(y,x,b){
y_hat = cbind(1,x)%*%b
loss = sum((y-y_hat)^2)
return(loss)
}
y = c(1,2,3,4,5,6)
x = c(2,4,-3,5,6,1)
b = c(1,0)
square_loss(y,x,b)
square_loss(y,x,b=c(1,1))
square_loss(y,x,b=c(0,-1))
sxx = sum((x-mean(x))^2)
sxx
## 최적해는 어떻게 구할것인가 ?
optimal_b = c(NA,NA)
sx = (x-mean(x))
sx
sy = (y-mean(y))
sy
sxy = sum(sx*sy)
sxy
optimal_b[2] = sxy/sxx
optimal_b
optimal_b[1] = mean(y) -optimal_b*mean(x)
optimal_b
optimal_b[1] = mean(y) -optimal_b*mean(x)
optimal_b[1] = mean(y) -optimal_b[2]*mean(x)
optimal_b
square_loss(y,x,b=optimal_b)
# 대입 10000번 하겠다.
b0.vec = seq(-10,10,length.out=100)
b1.vec = seq(-10,10,length.out=100)
loss.mat = matrix(NA,100,100)
for(i in b0.vec){
for(j in b1.vec){
b.vec = c(b0.vec[i],b1.vec[j])
loss.mat[i,j]=sq.loss.fun(y,x,b.vec)
}
}
for(i in b0.vec){
for(j in b1.vec){
b.vec = c(b0.vec[i],b1.vec[j])
loss.mat[i,j]=square_loss(y,x,b.vec)
}
}
for(i in b0.vec){
for(j in b1.vec){
b.vec = c(i,j)
loss.mat[i,j]=square_loss(y,x,b.vec)
}
}
contour(b0.vec,b1.vec,loss.mat,nlevels=100)
contour(b0.vec,b1.vec,loss.mat)
View(loss.mat)
y = c(3,-2,1)
x = c(-1,2,2)
b = c(1,0)
square_loss(y,x,b)
square_loss(y,x,b=c(1,1))
square_loss(y,x,b=c(0,-1))
## 최적해는 어떻게 구할것인가 ?
optimal_b = c(NA,NA)
sxx = sum((x-mean(x))^2)
sxx
sx = (x-mean(x))
sx
sy = (y-mean(y))
sy
sxy = sum(sx*sy)
sxy
optimal_b[2] = sxy/sxx
optimal_b
optimal_b[1] = mean(y) -optimal_b[2]*mean(x)
optimal_b
square_loss(y,x,b=optimal_b)
# 대입 10000번 하겠다.
b0.vec = seq(-10,10,length.out=100)
b1.vec = seq(-10,10,length.out=100)
loss.mat = matrix(NA,100,100)
for(i in b0.vec){
for(j in b1.vec){
b.vec = c(i,j)
loss.mat[i,j]=square_loss(y,x,b.vec)
}
}
contour(b0.vec,b1.vec,loss.mat)
for(i in c(1,2,3,4,5)){
return(i)}
for(i in c(1,2,3,4,5)){
print(i)}
for(i in c(1,2,3,4,5)){
for j in c(2,3,4,5{)
print(i,j)}
}
for(i in c(1,2,3,4,5)){
for j in c(2,3,4,5)
print(i,j)}
for(i in c(1,2,3,4,5)){
for j in c(2,3,4,5){
print(i,j)}}
for(i in c(1,2,3,4,5)){
for( j in c(2,3,4,5)){
print(i,j)
}
}
for(i in c(1,2,3,4,5)){
for( j in c(2,3,4,5)){
print(i+j)
}
}
for(i in c(1,2,3,4,5)){
for( j in c(2,3,4,5)){
print(cbind(i,j))
}
}
tt=[1,2,3]
cc=[3,2,1]
tt=c(1,2,3)
cc=c(3,2,1)
for(i in tt){
for( j in cc){
print(c(tt[i],cc[j]))
}
}
for(i in b0.vec){
for(j in b1.vec){
b.vec = c(b0.vec[i],b1.vec[j])
loss.mat[i,j]=square_loss(y,x,b.vec)
}
}
abs.loss.fun <- function(y,x,b){
r.vec = y - x%*%b
num = length(y)
loss = sum(abs(r.vec))/2/num
return (loss)
}
b = c(1,1)
y = c(3,-2,1)
x = (1,2,2)
abs.loss.fun <- function(y,x,b){
r.vec = y - x%*%b
num = length(y)
loss = sum(abs(r.vec))/2/num
return (loss)
}
b = c(1,1)
y = c(3,-2,1)
x = (1,2,2)
x1 = cbind(1,x)
x1 = cbind(1,x)
x = (1,2,2)
x =c(1,2,2)
x = cbind(1,x)
abs.loss.fun(y,x,b)
# 대입 10000번 하겠다.
b0.vec = seq(-10,10,length.out=100)
b1.vec = seq(-10,10,length.out=100)
loss.mat = matrix(NA,100,100)
abs.loss.fun <- function(y,x,b){
r.vec = y - x%*%b
num = length(y)
loss = sum(abs(r.vec))/2/num
return (loss)
}
b = c(1,1)
y = c(3,-2,1)
x =c(1,2,2)
x = cbind(1,x)
abs.loss.fun(y,x,b)
# 대입 10000번 하겠다.
b0.vec = seq(-10,10,length.out=100)
b1.vec = seq(-10,10,length.out=100)
loss.mat = matrix(NA,100,100)
for(i in b0.vec){
for(j in b1.vec){
b.vec = c(b0.vec[i],b1.vec[j])
loss.mat[i,j]=abs.loss.fun(y,x,b.vec)
}
}
b.vec = cbind(b0.vec[i],b1.vec[j])
for(i in b0.vec){
for(j in b1.vec){
b.vec = cbind(b0.vec[i],b1.vec[j])
loss.mat[i,j]=abs.loss.fun(y,x,b.vec)
}
}
for(i in b0.vec){
for(j in b1.vec){
b.vec = c(b0.vec[i],b1.vec[j])
loss.mat[i,j]=abs.loss.fun(y,x,b.vec)
}
}
