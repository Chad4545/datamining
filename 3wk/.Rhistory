square_loss=sqrt(sum((loss)^2)/dim(te.df)[1])
rst.mat[2,1]=square_loss
rst.mat
#L1
test_pred=cbind(1,te.df[,2])%*%coef(rq.fit)
loss=te.df[,1]-test_pred
aic.rq = aic.fun(loss)
rst.mat[1,2]=aic.rq
square_loss=sqrt(sum((loss)^2)/dim(te.df)[1])
rst.mat[2,2]=square_loss
rst.mat
#Huber
test_pred=cbind(1,te.df[,2])%*%coef(rb.fit)
loss=te.df[,1]-test_pred
aic.hub = aic.fun(loss)
rst.mat[1,3]=aic.hub
square_loss=sqrt(sum((loss)^2)/dim(te.df)[1])
aic.lm = aic.fun(loss)
rst.mat[2,3]=square_loss
rst.mat
# grid search for L1 & Huber
## tune `svm' for classification with RBF-kernel (default in svm),
## using one split for training/validation set
L2.mat = matrix(NA,2,100)
L2.mat
#colnames(L2.mat)=c("lm","rq","hub")
rownames(L2.mat)=c("AIC","Prediction")
L2.mat
colname=c()
iter = seq(0,1,length.out = 100)
for(j in 1:100){
for(k in iter){
colname <- c(colname, k)
rq.fit=rq(formula = sensitivity~V1,tau=k ,data=tr.df)
test_pred=cbind(1,te.df[,2])%*%coef(rq.fit)
loss=te.df[,1]-test_pred
aic.rq = aic.fun(loss)
L2.mat[1,j]=aic.rq
square_loss=sqrt(sum((loss)^2)/dim(te.df)[1])
L2.mat[2,j]=square_loss
}}
colnames(L2.mat)=colname
L2.mat
# grid search for L1 & Huber
## tune `svm' for classification with RBF-kernel (default in svm),
## using one split for training/validation set
L2.mat = matrix(NA,3,100)
L2.mat
#colnames(L2.mat)=c("lm","rq","hub")
rownames(L2.mat)=c("Tau","AIC","Prediction")
L2.mat
iter = seq(0,1,length.out = 100)
for(j in 1:100){
for(k in iter){
L2.mat[1,k]
rq.fit=rq(formula = sensitivity~V1,tau=k ,data=tr.df)
test_pred=cbind(1,te.df[,2])%*%coef(rq.fit)
loss=te.df[,1]-test_pred
aic.rq = aic.fun(loss)
L2.mat[2,j]=aic.rq
square_loss=sqrt(sum((loss)^2)/dim(te.df)[1])
L2.mat[3,j]=square_loss
}}
L2.mat
enumerate <- function(X, FUN, ...) {
result <- vector("list", length(X))
for (i in seq_along(result)) {
tmp <- FUN(X[[i]], i, ...)
if (is.null(tmp))
result[i] <- list(NULL)
else
result[[i]] <- tmp
}
result
}
enumerate(c(1,2,3,6,6,6,))
enumerate(c(1,2,3,6,6,6))
l <- list(a = 1, b = 2, c = 3)
enumerate(l, function(x, i) {
cat("Name:  ", names(l)[[i]], "\n")
cat("Value: ", x, "\n")
})
# grid search for L1 & Huber
## tune `svm' for classification with RBF-kernel (default in svm),
## using one split for training/validation set
L2.mat = matrix(NA,3,100)
L2.mat
#colnames(L2.mat)=c("lm","rq","hub")
rownames(L2.mat)=c("Tau","AIC","Prediction")
L2.mat
tau.tune=seq(0,1,length.out = 100)
for(j in 1:100){
L2.mat[1,j] = tau.tune[j]
rq.fit=rq(formula = sensitivity~V1,tau=tau.tune[j] ,data=tr.df)
test_pred=cbind(1,te.df[,2])%*%coef(rq.fit)
loss=te.df[,1]-test_pred
aic.rq = aic.fun(loss)
L2.mat[2,j]=aic.rq
square_loss=sqrt(sum((loss)^2)/dim(te.df)[1])
L2.mat[3,j]=square_loss
}
# data load
# train_data
df<-read.csv(file="old.sam.for.reg.fit.csv")
tr.df = df[,c(1,4)]
#test_data
test.df<-read.csv(file="old.sam.for.reg.pred.csv")
te.df =test.df[,c(1,4)]
# result matrix
rst.mat = matrix(NA,2,3)
colnames(rst.mat)=c("lm","rq","hub")
rownames(rst.mat)=c("AIC","Prediction")
rst.mat
#models = simple linear regression + L2, L1, huber
library(robustreg)
library(quantreg)
###############################################################3
#L2
lm.fit = lm(formula = sensitivity~V1,data=tr.df)
#L1
rq.fit=rq(formula = sensitivity~V1,data=tr.df)
#Huber
rb.fit=robustRegH(formula = sensitivity~V1,data=tr.df)
names(rb.fit) # "coefficients" "weights"      "mse"
aic.fun <- function(loss){
sse = sum((loss)^2)
return(log(sse/length(loss))+2*2/length(loss))
}
#L2
test_pred=cbind(1,te.df[,2])%*%coef(lm.fit)
loss=te.df[,1]-test_pred
aic.lm = aic.fun(loss)
rst.mat[1,1]=aic.lm
square_loss=sqrt(sum((loss)^2)/dim(te.df)[1])
rst.mat[2,1]=square_loss
rst.mat
#L1
test_pred=cbind(1,te.df[,2])%*%coef(rq.fit)
loss=te.df[,1]-test_pred
aic.rq = aic.fun(loss)
rst.mat[1,2]=aic.rq
square_loss=sqrt(sum((loss)^2)/dim(te.df)[1])
rst.mat[2,2]=square_loss
rst.mat
#Huber
test_pred=cbind(1,te.df[,2])%*%coef(rb.fit)
loss=te.df[,1]-test_pred
aic.hub = aic.fun(loss)
rst.mat[1,3]=aic.hub
square_loss=sqrt(sum((loss)^2)/dim(te.df)[1])
aic.lm = aic.fun(loss)
rst.mat[2,3]=square_loss
rst.mat
# grid search for L1 & Huber
## tune `svm' for classification with RBF-kernel (default in svm),
## using one split for training/validation set
L2.mat = matrix(NA,3,100)
L2.mat
#colnames(L2.mat)=c("lm","rq","hub")
rownames(L2.mat)=c("Tau","AIC","Prediction")
L2.mat
tau.tune=seq(0,1,length.out = 100)
for(j in 1:100){
L2.mat[1,j] = tau.tune[j]
rq.fit=rq(formula = sensitivity~V1,tau=tau.tune[j] ,data=tr.df)
test_pred=cbind(1,te.df[,2])%*%coef(rq.fit)
loss=te.df[,1]-test_pred
aic.rq = aic.fun(loss)
L2.mat[2,j]=aic.rq
square_loss=sqrt(sum((loss)^2)/dim(te.df)[1])
L2.mat[3,j]=square_loss
}
L2.mat
# grid search for L1 & [Huber]
hub.mat = matrix(NA,3,100)
hub.mat
#colnames(L2.mat)=c("lm","rq","hub")
rownames(Huber.mat)=c("delta","AIC","Prediction")
#colnames(L2.mat)=c("lm","rq","hub")
rownames(hub.mat)=c("delta","AIC","Prediction")
hub.mat
hub.tune=seq(1,3,length.out = 100)
hub.tune=seq(1,3,length.out = 100)
for(j in 1:100){
hub.mat[1,j] = hub.tune[j]
rb.fit=robustRegH(formula = sensitivity~V1,tune=hub.tune[j] ,data=tr.df)
test_pred=cbind(1,te.df[,2])%*%coef(rq.fit)
loss=te.df[,1]-test_pred
aic.rq = aic.fun(loss)
hub.mat[2,j]=aic.rq
square_loss=sqrt(sum((loss)^2)/dim(te.df)[1])
hub.mat[3,j]=square_loss
}
hub.mat
rst.mat
rst.mat
for(j in 1:100){
hub.mat[1,j] = hub.tune[j]
rb.fit=robustRegH(formula = sensitivity~V1,tune=hub.tune[j] ,data=tr.df)
test_pred=cbind(1,te.df[,2])%*%coef(rb.fit)
loss=te.df[,1]-test_pred
aic.hub = aic.fun(loss)
hub.mat[2,j]=aic.hub
square_loss=sqrt(sum((loss)^2)/dim(te.df)[1])
hub.mat[3,j]=square_loss
}
hub.mat
# grid search for L1 & [Huber]
hub.mat = matrix(NA,3,100)
hub.mat
#colnames(L2.mat)=c("lm","rq","hub")
rownames(hub.mat)=c("delta","AIC","Prediction")
hub.mat
hub.tune=seq(1,3,length.out = 100)
for(j in 1:100){
hub.mat[1,j] = hub.tune[j]
rb.fit=robustRegH(formula = sensitivity~V1,tune=hub.tune[j] ,data=tr.df)
test_pred=cbind(1,te.df[,2])%*%coef(rb.fit)
loss=te.df[,1]-test_pred
aic.hub = aic.fun(loss)
hub.mat[2,j]=aic.hub
square_loss=sqrt(sum((loss)^2)/dim(te.df)[1])
hub.mat[3,j]=square_loss
}
hub.mat
# grid search for [L1] & Huber
L2.mat = matrix(NA,3,100)
L2.mat
#colnames(L2.mat)=c("lm","rq","hub")
rownames(L2.mat)=c("Tau","AIC","Prediction")
L2.mat
tau.tune=seq(0,1,length.out = 100)
for(j in 1:100){
L2.mat[1,j] = tau.tune[j]
rq.fit=rq(formula = sensitivity~V1,tau=tau.tune[j] ,data=tr.df)
test_pred=cbind(1,te.df[,2])%*%coef(rq.fit)
loss=te.df[,1]-test_pred
aic.rq = aic.fun(loss)
L2.mat[2,j]=aic.rq
square_loss=sqrt(sum((loss)^2)/dim(te.df)[1])
L2.mat[3,j]=square_loss
}
L2.mat
plot(hub.mat[1,],hub.mat[2,])
plot(hub.mat[1,],hub.mat[3,])
plot(L2.mat[1,],L2.mat[2,])
plot(L2.mat[1,],L2.mat[3,])
?plot
plot(hub.mat[1,],hub.mat[2,])
title(main = "delta & AIC")
title(main = "Delta in Huber & AIC")
plot(hub.mat[1,],hub.mat[2,])
title(main = "Delta in Huber & AIC")
?plot
x <- seq(-4, 4, len = 101)
y <- cbind(sin(x), cos(x))
matplot(x, y, type = "l", xaxt = "n",
main = expression(paste(plain(sin) * phi, "  and  ",
plain(cos) * phi)),
ylab = expression("sin" * phi, "cos" * phi), # only 1st is taken
xlab = expression(paste("Phase Angle ", phi)),
col.main = "blue")
axis(1, at = c(-pi, -pi/2, 0, pi/2, pi),
labels = expression(-pi, -pi/2, 0, pi/2, pi))
abline(h = 0, v = pi/2 * c(-1,1), lty = 2, lwd = .1, col = "gray70")
plot(1, col.axis = "sky blue", col.lab = "thistle")
title("Main Title", sub = "sub title",
cex.main = 2,   font.main= 4, col.main= "blue",
cex.sub = 0.75, font.sub = 3, col.sub = "red")
x <- seq(-4, 4, len = 101)
y <- cbind(sin(x), cos(x))
matplot(x, y, type = "l", xaxt = "n",
main = expression(paste(plain(sin) * phi, "  and  ",
plain(cos) * phi)),
ylab = expression("sin" * phi, "cos" * phi), # only 1st is taken
xlab = expression(paste("Phase Angle ", phi)),
col.main = "blue")
axis(1, at = c(-pi, -pi/2, 0, pi/2, pi),
labels = expression(-pi, -pi/2, 0, pi/2, pi))
abline(h = 0, v = pi/2 * c(-1,1), lty = 2, lwd = .1, col = "gray70")
plot(1, col.axis = "sky blue", col.lab = "thistle")
title("Main Title", sub = "sub title",
cex.main = 2,   font.main= 4, col.main= "blue",
cex.sub = 0.75, font.sub = 3, col.sub = "red")
?matplot
matplot(hub.mat[1,],hub.mat[2,],type="h",)
title(main = "Delta in Huber & AIC")
x <- seq(-4, 4, len = 101)
y <- cbind(sin(x), cos(x))
matplot(x, y, type = "l", xaxt = "n",
main = expression(paste(plain(sin) * phi, "  and  ",
plain(cos) * phi)),
ylab = expression("sin" * phi, "cos" * phi), # only 1st is taken
xlab = expression(paste("Phase Angle ", phi)),
col.main = "blue")
matplot(hub.mat[1,],hub.mat[2,],type="h",
ylab = expression("AIC"),
xlab = expression("Delta"))
matplot(hub.mat[1,],hub.mat[3,],type="h",
ylab = expression("AIC"),
xlab = expression("loss"))
matplot(L2.mat[1,],hub.mat[2,],type="h",
ylab = expression("AIC"),
xlab = expression("Delta"))
matplot(L2.mat[1,],L2.mat[2,],type="h",
ylab = expression("AIC"),
xlab = expression("Delta"))
title(main = "Tau in L1 & AIC")
matplot(L2.mat[1,],L2.mat[2,],type="h",
ylab = expression("AIC"),
xlab = expression("Tau"))
title(main = "Tau in L1 & AIC")
matplot(L2.mat[1,],L2.mat[3,],type="h",
ylab = expression("Loss"),
xlab = expression("Tau"))
title(main = "Tau in L1 & Loss")
matplot(hub.mat[1,],hub.mat[2,],type="h",
ylab = expression("AIC"),
xlab = expression("Delta"))
title(main = "Delta in Huber & AIC")
matplot(hub.mat[1,],hub.mat[3,],type="h",
ylab = expression("AIC"),
xlab = expression("Loss"))
title(main = "Delta in Huber & Loss")
# grid search for L1 & [Huber]
hub.mat = matrix(NA,3,100)
hub.mat
#colnames(L2.mat)=c("lm","rq","hub")
rownames(hub.mat)=c("delta","AIC","Prediction")
hub.mat
hub.tune=seq(0,1.5,length.out = 100)
for(j in 1:100){
hub.mat[1,j] = hub.tune[j]
rb.fit=robustRegH(formula = sensitivity~V1,tune=hub.tune[j] ,data=tr.df)
test_pred=cbind(1,te.df[,2])%*%coef(rb.fit)
loss=te.df[,1]-test_pred
aic.hub = aic.fun(loss)
hub.mat[2,j]=aic.hub
square_loss=sqrt(sum((loss)^2)/dim(te.df)[1])
hub.mat[3,j]=square_loss
}
hub.tune=seq(0,1.5,length.out = 100)
for(j in 1:100){
hub.mat[1,j] = hub.tune[j]
rb.fit=robustRegH(formula = sensitivity~V1,tune=hub.tune[j] ,data=tr.df)
test_pred=cbind(1,te.df[,2])%*%coef(rb.fit)
loss=te.df[,1]-test_pred
aic.hub = aic.fun(loss)
hub.mat[2,j]=aic.hub
square_loss=sqrt(sum((loss)^2)/dim(te.df)[1])
hub.mat[3,j]=square_loss
}
hub.tune=seq(0,1,length.out = 100)
for(j in 1:100){
hub.mat[1,j] = hub.tune[j]
rb.fit=robustRegH(formula = sensitivity~V1,tune=hub.tune[j] ,data=tr.df)
test_pred=cbind(1,te.df[,2])%*%coef(rb.fit)
loss=te.df[,1]-test_pred
aic.hub = aic.fun(loss)
hub.mat[2,j]=aic.hub
square_loss=sqrt(sum((loss)^2)/dim(te.df)[1])
hub.mat[3,j]=square_loss
}
# data load
# train_data
df<-read.csv(file="old.sam.for.reg.fit.csv")
tr.df = df[,c(1,4)]
#test_data
test.df<-read.csv(file="old.sam.for.reg.pred.csv")
te.df =test.df[,c(1,4)]
# result matrix
rst.mat = matrix(NA,2,3)
colnames(rst.mat)=c("lm","rq","hub")
rownames(rst.mat)=c("AIC","Prediction")
rst.mat
#models = simple linear regression + L2, L1, huber
library(robustreg)
library(quantreg)
###############################################################3
#L2
lm.fit = lm(formula = sensitivity~V1,data=tr.df)
#L1
rq.fit=rq(formula = sensitivity~V1,data=tr.df)
#Huber
rb.fit=robustRegH(formula = sensitivity~V1,data=tr.df)
names(rb.fit) # "coefficients" "weights"      "mse"
aic.fun <- function(loss){
sse = sum((loss)^2)
return(log(sse/length(loss))+2*2/length(loss))
}
#L2
test_pred=cbind(1,te.df[,2])%*%coef(lm.fit)
loss=te.df[,1]-test_pred
aic.lm = aic.fun(loss)
rst.mat[1,1]=aic.lm
square_loss=sqrt(sum((loss)^2)/dim(te.df)[1])
rst.mat[2,1]=square_loss
rst.mat
#L1
test_pred=cbind(1,te.df[,2])%*%coef(rq.fit)
loss=te.df[,1]-test_pred
aic.rq = aic.fun(loss)
rst.mat[1,2]=aic.rq
square_loss=sqrt(sum((loss)^2)/dim(te.df)[1])
rst.mat[2,2]=square_loss
rst.mat
#Huber
test_pred=cbind(1,te.df[,2])%*%coef(rb.fit)
loss=te.df[,1]-test_pred
aic.hub = aic.fun(loss)
rst.mat[1,3]=aic.hub
square_loss=sqrt(sum((loss)^2)/dim(te.df)[1])
rst.mat[2,3]=square_loss
rst.mat
# grid search for [L1] & Huber
L2.mat = matrix(NA,3,100)
L2.mat
#colnames(L2.mat)=c("lm","rq","hub")
rownames(L2.mat)=c("Tau","AIC","Prediction")
L2.mat
tau.tune=seq(0,1,length.out = 100)
for(j in 1:100){
L2.mat[1,j] = tau.tune[j]
rq.fit=rq(formula = sensitivity~V1,tau=tau.tune[j] ,data=tr.df)
test_pred=cbind(1,te.df[,2])%*%coef(rq.fit)
loss=te.df[,1]-test_pred
aic.rq = aic.fun(loss)
L2.mat[2,j]=aic.rq
square_loss=sqrt(sum((loss)^2)/dim(te.df)[1])
L2.mat[3,j]=square_loss
}
L2.mat
# grid search for L1 & [Huber]
hub.mat = matrix(NA,3,100)
hub.mat
#colnames(L2.mat)=c("lm","rq","hub")
rownames(hub.mat)=c("delta","AIC","Prediction")
hub.mat
hub.tune=seq(0,1,length.out = 100)
for(j in 1:100){
hub.mat[1,j] = hub.tune[j]
rb.fit=robustRegH(formula = sensitivity~V1,tune=hub.tune[j] ,data=tr.df)
test_pred=cbind(1,te.df[,2])%*%coef(rb.fit)
loss=te.df[,1]-test_pred
aic.hub = aic.fun(loss)
hub.mat[2,j]=aic.hub
square_loss=sqrt(sum((loss)^2)/dim(te.df)[1])
hub.mat[3,j]=square_loss
}
for(j in 1:100){
hub.mat[1,j] = hub.tune[j]
rb.fit=robustRegH(formula = sensitivity~V1,tune=hub.tune[j] ,data=tr.df)
test_pred=cbind(1,te.df[,2])%*%coef(rb.fit)
loss=te.df[,1]-test_pred
aic.hub = aic.fun(loss)
hub.mat[2,j]=aic.hub
square_loss=sqrt(sum((loss)^2)/dim(te.df)[1])
hub.mat[3,j]=square_loss
}
# grid search for L1 & [Huber]
hub.mat = matrix(NA,3,100)
hub.mat
#colnames(L2.mat)=c("lm","rq","hub")
rownames(hub.mat)=c("delta","AIC","Prediction")
hub.mat
hub.tune=seq(0,1,length.out = 100)
for(j in 1:100){
hub.mat[1,j] = hub.tune[j]
rb.fit=robustRegH(formula = sensitivity~V1,tune=hub.tune[j] ,data=tr.df)
test_pred=cbind(1,te.df[,2])%*%coef(rb.fit)
loss=te.df[,1]-test_pred
aic.hub = aic.fun(loss)
hub.mat[2,j]=aic.hub
square_loss=sqrt(sum((loss)^2)/dim(te.df)[1])
hub.mat[3,j]=square_loss
}
hub.mat
matplot(hub.mat[1,],hub.mat[2,],type="h",
ylab = expression("AIC"),
xlab = expression("Delta"))
title(main = "Delta in Huber & AIC")
matplot(hub.mat[1,],hub.mat[3,],type="h",
ylab = expression("AIC"),
xlab = expression("Loss"))
title(main = "Delta in Huber & Loss")
matplot(L2.mat[1,],L2.mat[2,],type="h",
ylab = expression("AIC"),
xlab = expression("Tau"))
title(main = "Tau in L1 & AIC")
matplot(L2.mat[1,],L2.mat[3,],type="h",
ylab = expression("Loss"),
xlab = expression("Tau"))
title(main = "Tau in L1 & Loss")
plot(L2.mat[1,],L2.mat[2,])
plot(L2.mat[1,],L2.mat[3,])
# grid search for L1 & [Huber]
hub.mat = matrix(NA,3,100)
hub.mat
#colnames(L2.mat)=c("lm","rq","hub")
rownames(hub.mat)=c("delta","AIC","Prediction")
hub.mat
hub.tune=seq(0,1,length.out = 100)
for(j in 1:100){
hub.mat[1,j] = hub.tune[j]
rb.fit=robustRegH(formula = sensitivity~V1,tune=hub.tune[j] ,data=tr.df)
test_pred=cbind(1,te.df[,2])%*%coef(rb.fit)
loss=te.df[,1]-test_pred
aic.hub = aic.fun(loss)
hub.mat[2,j]=aic.hub
square_loss=sqrt(sum((loss)^2)/dim(te.df)[1])
hub.mat[3,j]=square_loss
}
